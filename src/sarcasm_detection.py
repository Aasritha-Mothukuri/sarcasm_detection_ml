# -*- coding: utf-8 -*-
"""sarcasm_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c0OhZ5GpiCHaM9DzyWk-KDj4DiHE19vr
"""

# Step 1: Dataset Collection
!wget https://raw.githubusercontent.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection/master/Sarcasm_Headlines_Dataset.json

import pandas as pd
data = pd.read_json("Sarcasm_Headlines_Dataset.json", lines=True)
print("Dataset Shape:", data.shape)

# Cell 2: Drop Unnecessary Columns and Preprocessing Setup

data = data.drop(columns=['article_link'])

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    words = text.split()
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return ' '.join(words)

data['clean_headline'] = data['headline'].apply(clean_text)
print(data[['headline', 'clean_headline', 'is_sarcastic']].head())

# Cell 3: Split Data into Training and Testing Sets

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    data['clean_headline'], data['is_sarcastic'], test_size=0.2, random_state=42
)

print(f"Training samples: {len(X_train)}")
print(f"Testing samples: {len(X_test)}")

# Cell 4: Feature Extraction with TF-IDF Vectorizer

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

print(f"Shape of X_train_tfidf: {X_train_tfidf.shape}")
print(f"Shape of X_test_tfidf: {X_test_tfidf.shape}")

# Cell 5: Train and Evaluate Logistic Regression

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train_tfidf, y_train)
y_pred_logreg = logreg.predict(X_test_tfidf)

acc_logreg = accuracy_score(y_test, y_pred_logreg)
print(f"Logistic Regression Accuracy: {acc_logreg:.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred_logreg))

# Cell 6: Train and Evaluate Naive Bayes

from sklearn.naive_bayes import MultinomialNB

nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train)
y_pred_nb = nb.predict(X_test_tfidf)

acc_nb = accuracy_score(y_test, y_pred_nb)
print(f"Naive Bayes Accuracy: {acc_nb:.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred_nb))

# Cell 7: Train and Evaluate Support Vector Machine (SVM)

from sklearn.svm import SVC

svm = SVC(kernel='linear')
svm.fit(X_train_tfidf, y_train)
y_pred_svm = svm.predict(X_test_tfidf)

acc_svm = accuracy_score(y_test, y_pred_svm)
print(f"SVM Accuracy: {acc_svm:.4f}")
print("Classification Report:\n", classification_report(y_test, y_pred_svm))

# Function from before
def predict_sarcasm(text, model, vectorizer):
    text_clean = clean_text(text)
    text_vec = vectorizer.transform([text_clean])
    prediction = model.predict(text_vec)
    return "Sarcastic" if prediction[0] == 1 else "Not Sarcastic"

# Take input from user
user_input = input("Enter a sentence to check if it is sarcastic: ")

# Predict sarcasm
result = predict_sarcasm(user_input, nb, vectorizer)

print(f"Prediction: {result}")